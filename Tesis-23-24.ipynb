{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7520dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import unicodedata\n",
    "from docx import Document\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a69c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTADO DE SITUIACIONA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b2b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PYMSEPARADA23S', 'PYMEINDIVU23S', 'PLENASEPARA23S', 'PLENAINDIVIDU23S'])\n"
     ]
    }
   ],
   "source": [
    "def leer_excel_con_pandas(ruta_archivo):\n",
    "    # Leer archivo Excel, hoja por defecto (la primera)\n",
    "    df23 = pd.read_excel(ruta_archivo,sheet_name=None)\n",
    "    return df23\n",
    "# ESTADO DE SITUACION FINANCIERA 2023\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_excel = r\"C:\\Users\\acerquera\\OneDrive - Media Investment Optimization S.A\\Escritorio\\estadistica\\udea\\TESIS-QUIEBRA\\BASE DE DATOS\\añp 2023\\ESTADOSITUACION23.xlsx\"  # Cambia si está en otra ruta\n",
    "    df23 = leer_excel_con_pandas(ruta_excel)\n",
    "    print(df23.keys())  # Mostrar nombres de las hojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627911ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los nombres de las columnas de cada hoja en filas\n",
    "for nombre_hoja, data in df23.items():\n",
    "    print(f\"Hoja: {nombre_hoja}\")\n",
    "    print(list(data.columns))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre_hoja, hoja_df in df23.items():\n",
    "    print(f\"Hoja: {nombre_hoja} - Número de columnas: {hoja_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5344a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los nombres de columnas de cada hoja\n",
    "columnas_por_hoja = {nombre_hoja: set(data.columns) for nombre_hoja, data in df23.items()}\n",
    "\n",
    "# Intersección de columnas entre todas las hojas\n",
    "columnas_comunes = set.intersection(*columnas_por_hoja.values())\n",
    "print(\"Columnas con el mismo nombre en todas las hojas:\")\n",
    "for col in columnas_comunes:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTADO DE RESULTADOS 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5949c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTADODERESULTADO 2023\n",
    "def leer_excel_con_pandas(ruta_archivo):\n",
    "    # Leer archivo Excel, hoja por defecto (la primera)\n",
    "    dfa23 = pd.read_excel(ruta_archivo,sheet_name=None)\n",
    "    return dfa23\n",
    "# ESTADO DE RESULTADOS 2023\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_excel_resultado = r\"C:\\Users\\acerquera\\OneDrive - Media Investment Optimization S.A\\Escritorio\\estadistica\\udea\\TESIS-QUIEBRA\\BASE DE DATOS\\añp 2023\\ESTADORESULTADO23.xlsx\"  # Cambia si está en otra ruta\n",
    "    dfa23 = leer_excel_con_pandas(ruta_excel_resultado)\n",
    "    print(dfa23.keys())  # Mostrar nombres de las hojas\n",
    "\n",
    "\n",
    "for nombre_hoja, data in dfa23.items():\n",
    "    print(f\"Hoja: {nombre_hoja}\")\n",
    "    print(list(data.columns))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la intersección de columnas entre todas las hojas de dfa23\n",
    "columnas_por_hoja = {nombre_hoja: set(data.columns) for nombre_hoja, data in dfa23.items() if not data.empty}\n",
    "columnas_comunes = set.intersection(*columnas_por_hoja.values())\n",
    "print(\"Columnas en común en todas las hojas de dfa23:\")\n",
    "for col in columnas_comunes:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750c65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAMOS LOS DICCIONARIOS 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAMOS EL DICCIONARIO----------------------------PARA BALANCE GENERAL 2023\n",
    "# Copiar todas las hojas de `df23` a un diccionario llamado `balances23`\n",
    "balances23 = {nombre_hoja: hoja.copy() for nombre_hoja, hoja in df23.items()}\n",
    "\n",
    "# Resumen rápido\n",
    "print(\"Hojas cargadas en 'balances23':\", list(balances23.keys()))\n",
    "for nombre, hoja in balances23.items():\n",
    "    print(f\"{nombre}: {hoja.shape[0]} filas x {hoja.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### CREACION DE DICCIONARIO #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar todas las hojas de `dfa23` a un diccionario llamado `resultados23`\n",
    "resultados23 = {nombre_hoja: hoja.copy() for nombre_hoja, hoja in dfa23.items()}\n",
    "\n",
    "# Resumen rápido\n",
    "print(\"Hojas cargadas en 'resultados23':\", list(resultados23.keys()))\n",
    "for nombre, hoja in resultados23.items():\n",
    "    print(f\"{nombre}: {hoja.shape[0]} filas x {hoja.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## MAPEOS DE HOJAS ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d852a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREACION DE MAPEOS DE AMBAS HOJAS\n",
    "\n",
    "mapeo = {\n",
    "'PYMSEPARADA23S':   'PYMESEPARA23R',\n",
    "'PYMEINDIVU23S':    'PYMEINDIV23R',\n",
    "'PLENASEPARA23S':   'PLENASEPADA23R',\n",
    "'PLENAINDIVIDU23S': 'PLENAINDIVI23R'\n",
    "}\n",
    "\n",
    "fusionados = {}\n",
    "for hoja_balance, hoja_resultado in mapeo.items():\n",
    "    df_balance_23 = balances23[hoja_balance]\n",
    "    df_resultado_23 = resultados23[hoja_resultado]\n",
    "    \n",
    "    # Filtrar solo Periodo Actual y Fecha de Corte = 2023-12-31\n",
    "    df_balance_filtrado = df_balance_23[\n",
    "        (df_balance_23[\"Periodo\"] == \"Periodo Actual\") &\n",
    "        (df_balance_23[\"Fecha_de_Corte\"] == \"2023-12-31\")\n",
    "    ].drop_duplicates(subset=[\"NIT\", \"Periodo\", \"Fecha_de_Corte\"])\n",
    "    \n",
    "    df_resultado_filtrado = df_resultado_23[\n",
    "        (df_resultado_23[\"Periodo\"] == \"Periodo Actual\") &\n",
    "        (df_resultado_23[\"Fecha_de_Corte\"] == \"2023-12-31\")\n",
    "    ].drop_duplicates(subset=[\"NIT\", \"Periodo\", \"Fecha_de_Corte\"])\n",
    "    \n",
    "    print(f\"Para {hoja_balance}: df_balance_filtrado tiene {len(df_balance_filtrado)} filas\")\n",
    "    print(f\"Para {hoja_resultado}: df_resultado_filtrado tiene {len(df_resultado_filtrado)} filas\")\n",
    "    \n",
    "    # Hacer el merge\n",
    "    df_fusionado = pd.merge(\n",
    "        df_balance_filtrado,\n",
    "        df_resultado_filtrado,\n",
    "        on=[\"NIT\", \"Periodo\", \"Fecha_de_Corte\"],\n",
    "        suffixes=('_balance', '_resultado'),\n",
    "        how='inner'\n",
    "    )\n",
    "    print(f\"Merge para {hoja_balance} y {hoja_resultado}: {len(df_fusionado)} filas fusionadas\")\n",
    "    \n",
    "    fusionados[hoja_balance] = df_fusionado\n",
    "\n",
    "# Mostrar resumen de hojas fusionadas\n",
    "print(\"\\nResumen final de fusionados:\")\n",
    "for nombre, df in fusionados.items():\n",
    "    print(f\"{nombre}: {df.shape[0]} filas x {df.shape[1]} columnas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc641d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### DATAFRAMES COMBNNAODS 2023 ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8704fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los dataframes fusionados en uno solo\n",
    "df_final_23 = pd.concat(fusionados.values(), ignore_index=True)\n",
    "print(f\"Dataframe final: {df_final_23.shape[0]} filas x {df_final_23.shape[1]} columnas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCARGAR EXCEL--------------------------------------------------\n",
    "# Guardar como Excel\n",
    "df_final_23.to_excel('datos_fusionados_completos_23.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### dataframe df_final_23 ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar todas las columnas una por línea\n",
    "print(\"Columnas disponibles en df_final:\")\n",
    "for columna in df_final_23.columns:\n",
    "    print(columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir listas de columnas\n",
    "columnas_identificacion = [\n",
    "    'Punto de Entrada_balance',\n",
    "    'Nombre Formulario_balance',\n",
    "    'NIT',\n",
    "    'Fecha_de_Corte',\n",
    "    'año_balance',\n",
    "    'Razón social de la sociedad_balance',\n",
    "    'Clasificación Industrial Internacional Uniforme Versión 4 A.C (CIIU)_balance',\n",
    "    'Tipo societario_balance',\n",
    "    'Periodo',\n",
    "    'Punto de Entrada_resultado',\n",
    "    'Nombre Formulario_resultado',\n",
    "    'año_resultado',\n",
    "    'Razón social de la sociedad_resultado',\n",
    "    'Clasificación Industrial Internacional Uniforme Versión 4 A.C (CIIU)_resultado',\n",
    "    'Tipo societario_resultado'\n",
    "]\n",
    "\n",
    "columnas_calculo = [\n",
    "    'CurrentAssets', 'CurrentLiabilities', 'CashAndCashEquivalents',\n",
    "    'Revenue', 'Assets', 'GrossProfit', 'ProfitLossFromContinuingOperations',\n",
    "    'ProfitLoss', 'Equity', 'Inventories', 'CostOfSales',\n",
    "    'TradeAndOtherCurrentReceivables', 'Liabilities',\n",
    "    'OtherCurrentFinancialLiabilities', 'OtherNoncurrentFinancialLiabilities',\n",
    "    'NoncurrentLiabilities', 'FinanceCosts',\n",
    "     # NUEVAS VARIABLES PARA CTNO PRECISO\n",
    "    'Cuentas comerciales por cobrar y otras cuentas por cobrar corrientes (TradeAndOtherCurrentReceivables)',\n",
    "    'Inventarios corrientes (Inventories)',\n",
    "    'Otros activos no financieros corrientes (OtherCurrentNonfinancialAssets)',\n",
    "    'Activos por impuestos corrientes, corriente (CurrentTaxAssetsCurrent)',\n",
    "    'Cuentas por pagar comerciales y otras cuentas por pagar corrientes (TradeAndOtherCurrentPayables)',\n",
    "    'Provisiones corrientes por beneficios a los empleados (CurrentProvisionsForEmployeeBenefits)',\n",
    "    'Otros pasivos no financieros corrientes (OtherCurrentNonfinancialLiabilities)',\n",
    "    'Pasivos por impuestos corrientes, corriente (CurrentTaxLiabilitiesCurrent)',\n",
    "    \n",
    "    # NUEVA VARIABLE PARA FCLO/VENTAS\n",
    "    'Ganancia (pérdida) por actividades de operación (ProfitLossFromOperatingActivities)'\n",
    "\n",
    "]\n",
    "\n",
    "# Verificar qué columnas están disponibles\n",
    "columnas_disponibles = [col for col in columnas_identificacion + columnas_calculo if col in df_final_23.columns]\n",
    "columnas_faltantes = [col for col in columnas_identificacion + columnas_calculo if col not in df_final_23.columns]\n",
    "\n",
    "print(\"Columnas disponibles:\", len(columnas_disponibles))\n",
    "print(\"Columnas faltantes:\", columnas_faltantes)\n",
    "\n",
    "# Crear un nuevo DataFrame con solo las columnas necesarias\n",
    "df_seleccionado_23 = df_final_23[columnas_disponibles].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb758cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# dataframe df_seleccionado_23 #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e375b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de nombres simples a nombres completos en el DataFrame\n",
    "mapeo_nombres = {\n",
    "    'CurrentAssets': 'Activos corrientes totales (CurrentAssets)',\n",
    "    'CurrentLiabilities': 'Pasivos corrientes totales (CurrentLiabilities)',\n",
    "    'CashAndCashEquivalents': 'Efectivo y equivalentes al efectivo (CashAndCashEquivalents)',\n",
    "    'Revenue': 'Ingresos de actividades ordinarias (Revenue)',\n",
    "    'Assets': 'Total de activos (Assets)',\n",
    "    'GrossProfit': 'Ganancia bruta (GrossProfit)',\n",
    "    'ProfitLossFromContinuingOperations': 'Ganancia (pérdida) procedente de operaciones continuadas (ProfitLossFromContinuingOperations)',\n",
    "    'ProfitLoss': 'Ganancia (pérdida) (ProfitLoss)',\n",
    "    'Equity': 'Patrimonio total (Equity)',\n",
    "    'Inventories': 'Inventarios corrientes (Inventories)',\n",
    "    'CostOfSales': 'Costo de ventas (CostOfSales)',\n",
    "    'TradeAndOtherCurrentReceivables': 'Cuentas comerciales por cobrar y otras cuentas por cobrar corrientes (TradeAndOtherCurrentReceivables)',\n",
    "    'Liabilities': 'Total pasivos (Liabilities)',\n",
    "    'OtherCurrentFinancialLiabilities': 'Otros pasivos financieros corrientes (OtherCurrentFinancialLiabilities)',\n",
    "    'OtherNoncurrentFinancialLiabilities': 'Otros pasivos financieros no corrientes (OtherNoncurrentFinancialLiabilities)',\n",
    "    'NoncurrentLiabilities': 'Total de pasivos no corrientes (NoncurrentLiabilities)',\n",
    "    'FinanceCosts': 'Costos financieros (FinanceCosts)',\n",
    "    # NUEVAS VARIABLES PARA CTNO PRECISO\n",
    "    'OtherCurrentNonfinancialAssets': 'Otros activos no financieros corrientes (OtherCurrentNonfinancialAssets)',\n",
    "    'CurrentTaxAssetsCurrent': 'Activos por impuestos corrientes, corriente (CurrentTaxAssetsCurrent)',\n",
    "    'TradeAndOtherCurrentPayables': 'Cuentas por pagar comerciales y otras cuentas por pagar corrientes (TradeAndOtherCurrentPayables)',\n",
    "    'CurrentProvisionsForEmployeeBenefits': 'Provisiones corrientes por beneficios a los empleados (CurrentProvisionsForEmployeeBenefits)',\n",
    "    'OtherCurrentNonfinancialLiabilities': 'Otros pasivos no financieros corrientes (OtherCurrentNonfinancialLiabilities)',\n",
    "    'CurrentTaxLiabilitiesCurrent': 'Pasivos por impuestos corrientes, corriente (CurrentTaxLiabilitiesCurrent)',\n",
    "    \n",
    "    # NUEVA VARIABLE PARA FCLO/VENTAS\n",
    "    'ProfitLossFromOperatingActivities': 'Ganancia (pérdida) por actividades de operación (ProfitLossFromOperatingActivities)'\n",
    "\n",
    "}\n",
    "\n",
    "# Verificar qué columnas del mapeo están disponibles en df_final_23\n",
    "columnas_calculo_disponibles = []\n",
    "for nombre_simple, nombre_completo in mapeo_nombres.items():\n",
    "    if nombre_completo in df_final_23.columns:\n",
    "        columnas_calculo_disponibles.append(nombre_completo)\n",
    "        print(f\"✓ {nombre_simple} → {nombre_completo}\")\n",
    "    else:\n",
    "        print(f\"✗ {nombre_simple} → NO ENCONTRADO\")\n",
    "\n",
    "# Columnas de identificación (buscamos los nombres exactos)\n",
    "columnas_identificacion = [\n",
    "    'Punto de Entrada_balance',\n",
    "    'Nombre Formulario_balance',\n",
    "    'NIT',\n",
    "    'Fecha_de_Corte',\n",
    "    'año_balance',\n",
    "    'Razón social de la sociedad_balance',\n",
    "    'Clasificación Industrial Internacional Uniforme Versión 4 A.C (CIIU)_balance',\n",
    "    'Tipo societario_balance',\n",
    "    'Periodo',\n",
    "    'Punto de Entrada_resultado',\n",
    "    'Nombre Formulario_resultado',\n",
    "    'año_resultado',\n",
    "    'Razón social de la sociedad_resultado',\n",
    "    'Clasificación Industrial Internacional Uniforme Versión 4 A.C (CIIU)_resultado',\n",
    "    'Tipo societario_resultado'\n",
    "]\n",
    "\n",
    "# Filtrar solo las columnas de identificación disponibles\n",
    "columnas_identificacion_disponibles = [col for col in columnas_identificacion if col in df_final_23.columns]\n",
    "\n",
    "# Crear nuevo DataFrame con todas las columnas necesarias\n",
    "df_seleccionado_23 = df_final_23[columnas_identificacion_disponibles + columnas_calculo_disponibles].copy()\n",
    "\n",
    "# Renombrar columnas a nombres simples para facilitar los cálculos\n",
    "# Creamos un mapeo inverso: nombre_completo -> nombre_simple\n",
    "mapeo_renombre = {}\n",
    "for nombre_simple, nombre_completo in mapeo_nombres.items():\n",
    "    if nombre_completo in df_seleccionado_23.columns:\n",
    "        mapeo_renombre[nombre_completo] = nombre_simple\n",
    "\n",
    "df_seleccionado_23 = df_seleccionado_23.rename(columns=mapeo_renombre)\n",
    "\n",
    "print(f\"\\nDataFrame seleccionado: {df_seleccionado_23.shape[0]} filas x {df_seleccionado_23.shape[1]} columnas\")\n",
    "print(\"Columnas disponibles después del renombrado:\")\n",
    "for col in df_seleccionado_23.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37941e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora calcular todos los indicadores financieros paso a paso\n",
    "print(\"\\nCalculando indicadores financieros...\")\n",
    "\n",
    "# 1. Razón Corriente (raz)\n",
    "df_seleccionado_23['raz'] = df_seleccionado_23['CurrentAssets'] / df_seleccionado_23['CurrentLiabilities']\n",
    "\n",
    "# 2. Razón de Tesorería (teso)\n",
    "df_seleccionado_23['teso'] = df_seleccionado_23['CashAndCashEquivalents'] / df_seleccionado_23['CurrentLiabilities']\n",
    "\n",
    "# 3. Rotación de Activos (rota)\n",
    "df_seleccionado_23['rota'] = df_seleccionado_23['Revenue'] / df_seleccionado_23['Assets']\n",
    "\n",
    "# 4. Margen Bruto (margenb)\n",
    "df_seleccionado_23['margenb'] = df_seleccionado_23['GrossProfit'] / df_seleccionado_23['Revenue']\n",
    "\n",
    "# 5. ELIMINADO: Margen Operacional (margenop) - AHORA USAMOS margen_operacional\n",
    "# (Se calcula más abajo en las nuevas variables)\n",
    "\n",
    "# 6. Margen Neto (margen)\n",
    "df_seleccionado_23['margen'] = df_seleccionado_23['ProfitLoss'] / df_seleccionado_23['Revenue']\n",
    "\n",
    "# 7. Rentabilidad del Activo (ractiv)\n",
    "df_seleccionado_23['ractiv'] = df_seleccionado_23['ProfitLoss'] / df_seleccionado_23['Assets']\n",
    "\n",
    "# 8. Rentabilidad del Patrimonio (rpatri)\n",
    "df_seleccionado_23['rpatri'] = df_seleccionado_23['ProfitLoss'] / df_seleccionado_23['Equity']\n",
    "\n",
    "# 9. Ciclo Operacional (cicop)\n",
    "df_seleccionado_23['cicop'] = (df_seleccionado_23['Inventories'] / df_seleccionado_23['CostOfSales'] * 365 + \n",
    "                           df_seleccionado_23['TradeAndOtherCurrentReceivables'] / df_seleccionado_23['Revenue'] * 365)\n",
    "\n",
    "# 10. Endeudamiento Financiero (endeu)\n",
    "df_seleccionado_23['endeu'] = (df_seleccionado_23['OtherCurrentFinancialLiabilities'] + \n",
    "                           df_seleccionado_23['OtherNoncurrentFinancialLiabilities']) / df_seleccionado_23['Revenue']\n",
    "\n",
    "# 11. Nivel de Endeudamiento (niven)\n",
    "df_seleccionado_23['niven'] = df_seleccionado_23['Liabilities'] / df_seleccionado_23['Assets']\n",
    "\n",
    "# 12. Nivel de Endeudamiento Alternativo (nivel_endeudamiento_alt)\n",
    "df_seleccionado_23['nivel_endeudamiento_alt'] = df_seleccionado_23['Liabilities'] / (df_seleccionado_23['Liabilities'] + df_seleccionado_23['Equity'])\n",
    "\n",
    "# 13. Apalancamiento Corto Plazo (apalc)\n",
    "df_seleccionado_23['apalc'] = df_seleccionado_23['CurrentLiabilities'] / df_seleccionado_23['Equity']\n",
    "\n",
    "# 14. Apalancamiento Largo Plazo (apallar)\n",
    "df_seleccionado_23['apallar'] = df_seleccionado_23['NoncurrentLiabilities'] / df_seleccionado_23['Equity']\n",
    "\n",
    "# 15. Apalancamiento Financiero (apalfin)\n",
    "df_seleccionado_23['apalfin'] = (df_seleccionado_23['OtherCurrentFinancialLiabilities'] + \n",
    "                             df_seleccionado_23['OtherNoncurrentFinancialLiabilities']) / df_seleccionado_23['Equity']\n",
    "\n",
    "# 16. Apalancamiento Total (apaltot)\n",
    "df_seleccionado_23['apaltot'] = df_seleccionado_23['Liabilities'] / df_seleccionado_23['Equity']\n",
    "\n",
    "# 17. Cobertura de Intereses (cobint)\n",
    "if 'ProfitLossFromContinuingOperations' in df_seleccionado_23.columns and 'FinanceCosts' in df_seleccionado_23.columns:\n",
    "    df_seleccionado_23['cobint'] = df_seleccionado_23['ProfitLossFromContinuingOperations'] / df_seleccionado_23['FinanceCosts']\n",
    "    print(\"✓ Cobertura de Intereses calculada con ProfitLossFromContinuingOperations\")\n",
    "elif 'EBIT' in df_seleccionado_23.columns and 'FinanceCosts' in df_seleccionado_23.columns:\n",
    "    df_seleccionado_23['cobint'] = df_seleccionado_23['EBIT'] / df_seleccionado_23['FinanceCosts']\n",
    "    print(\"✓ Cobertura de Intereses calculada con EBIT\")\n",
    "else:\n",
    "    print(\"⚠ No se pudo calcular Cobertura de Intereses - columnas faltantes\")\n",
    "\n",
    "# 18. Total Activo/Total Pasivo (activos_pasivos)\n",
    "df_seleccionado_23['activos_pasivos'] = df_seleccionado_23['Assets'] / df_seleccionado_23['Liabilities']\n",
    "\n",
    "# 19. Pasivo Corto Plazo/Total Pasivo (pasivo_corto_pasivo_total)\n",
    "df_seleccionado_23['pasivo_corto_pasivo_total'] = df_seleccionado_23['CurrentLiabilities'] / df_seleccionado_23['Liabilities']\n",
    "\n",
    "# NUEVAS VARIABLES SOLICITADAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CALCULANDO LAS 3 NUEVAS VARIABLES SOLICITADAS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 20. MARGEN OPERACIONAL (margen_operacional) - Versión precisa\n",
    "if 'ProfitLossFromContinuingOperations' in df_seleccionado_23.columns and 'Revenue' in df_seleccionado_23.columns:\n",
    "    df_seleccionado_23['margen_operacional'] = df_seleccionado_23['ProfitLossFromContinuingOperations'] / df_seleccionado_23['Revenue']\n",
    "    print(\"✓ Margen Operacional calculado\")\n",
    "\n",
    "# 21. CTNO/VENTAS PRECISO (ctno_ventas_preciso) - Capital Trabajo Neto Operacional / Ventas\n",
    "try:\n",
    "    # Activos Corrientes Operacionales\n",
    "    activos_operacionales = (\n",
    "        df_seleccionado_23['TradeAndOtherCurrentReceivables'].fillna(0) +\n",
    "        df_seleccionado_23['Inventories'].fillna(0) +\n",
    "        df_seleccionado_23['OtherCurrentNonfinancialAssets'].fillna(0) +\n",
    "        df_seleccionado_23['CurrentTaxAssetsCurrent'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Pasivos Corrientes Operacionales\n",
    "    pasivos_operacionales = (\n",
    "        df_seleccionado_23['TradeAndOtherCurrentPayables'].fillna(0) +\n",
    "        df_seleccionado_23['CurrentProvisionsForEmployeeBenefits'].fillna(0) +\n",
    "        df_seleccionado_23['OtherCurrentNonfinancialLiabilities'].fillna(0) +\n",
    "        df_seleccionado_23['CurrentTaxLiabilitiesCurrent'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # CTNO preciso\n",
    "    df_seleccionado_23['ctno_preciso'] = activos_operacionales - pasivos_operacionales\n",
    "    df_seleccionado_23['ctno_ventas_preciso'] = df_seleccionado_23['ctno_preciso'] / df_seleccionado_23['Revenue']\n",
    "    print(\"✓ CTNO/Ventas PRECISO calculado\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"⚠ Error calculando CTNO: {e}\")\n",
    "\n",
    "# 22. FCLO/VENTAS (fclo_ventas) - Flujo Caja Operacional / Ventas\n",
    "if 'ProfitLossFromOperatingActivities' in df_seleccionado_23.columns and 'Revenue' in df_seleccionado_23.columns:\n",
    "    df_seleccionado_23['fclo_ventas'] = df_seleccionado_23['ProfitLossFromOperatingActivities'] / df_seleccionado_23['Revenue']\n",
    "    print(\"✓ FCLO/Ventas calculado\")\n",
    "else:\n",
    "    print(\"⚠ No se pudo calcular FCLO/Ventas\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIN NUEVAS VARIABLES\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reemplazar infinitos por NaN\n",
    "df_seleccionado_23 = df_seleccionado_23.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Lista de todos los indicadores calculados\n",
    "indicadores_calculados = [\n",
    "    'raz', 'teso', 'rota', 'margenb', 'margenop', 'margen', \n",
    "    'ractiv', 'rpatri', 'cicop', 'endeu', 'niven', \n",
    "    'nivel_endeudamiento_alt', 'apalc', 'apallar', \n",
    "    'apalfin', 'apaltot', 'cobint', 'activos_pasivos', \n",
    "    'pasivo_corto_pasivo_total',\n",
    "    #nuevas VARIABLES\n",
    "    'margen_operacional', 'ctno_ventas_preciso', 'fclo_ventas', \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Filtrar solo los indicadores que se calcularon exitosamente\n",
    "indicadores_calculados = [col for col in indicadores_calculados if col in df_seleccionado_23.columns]\n",
    "\n",
    "# Crear el DataFrame final con columnas de identificación e indicadores\n",
    "columnas_finales = columnas_identificacion_disponibles + indicadores_calculados\n",
    "df_final_indicadores = df_seleccionado_23[columnas_finales]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN FINAL DEL DATAFRAME CON INDICADORES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dimensiones: {df_final_indicadores.shape[0]} filas x {df_final_indicadores.shape[1]} columnas\")\n",
    "print(f\"Indicadores calculados exitosamente: {len(indicadores_calculados)}\")\n",
    "\n",
    "# Verificar valores nulos en los indicadores\n",
    "print(\"\\nVALORES NULOS POR INDICADOR:\")\n",
    "print(\"-\" * 40)\n",
    "for indicador in indicadores_calculados:\n",
    "    nulos = df_final_indicadores[indicador].isnull().sum()\n",
    "    total = len(df_final_indicadores)\n",
    "    porcentaje = nulos / total * 100\n",
    "    print(f\"{indicador:25s}: {nulos:5d} nulos ({porcentaje:6.2f}%)\")\n",
    "\n",
    "# Crear nuevo DataFrame final\n",
    "df_nuevo_final_23 = df_final_indicadores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7df4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables base usadas en los cálculos de indicadores\n",
    "variables_base = [\n",
    "    'CurrentAssets',\n",
    "    'CurrentLiabilities',\n",
    "    'CashAndCashEquivalents',\n",
    "    'Revenue',\n",
    "    'Assets',\n",
    "    'GrossProfit',\n",
    "    'ProfitLossFromContinuingOperations',\n",
    "    'ProfitLoss',\n",
    "    'Equity',\n",
    "    'Inventories',\n",
    "    'CostOfSales',\n",
    "    'TradeAndOtherCurrentReceivables',\n",
    "    'Liabilities',\n",
    "    'OtherCurrentFinancialLiabilities',\n",
    "    'OtherNoncurrentFinancialLiabilities',\n",
    "    'NoncurrentLiabilities',\n",
    "    'FinanceCosts'\n",
    "]\n",
    "\n",
    "# Filtrar las que realmente existen en df_seleccionado_23\n",
    "variables_base_disponibles = [v for v in variables_base if v in df_seleccionado_23.columns]\n",
    "\n",
    "# Crear DataFrame final con identificadores, indicadores y variables base\n",
    "columnas_finales = columnas_identificacion_disponibles + indicadores_calculados + variables_base_disponibles\n",
    "df_final_indicadores = df_seleccionado_23[columnas_finales]\n",
    "\n",
    "# Copiar a df_nuevo_final_23\n",
    "df_nuevo_final_23= df_final_indicadores.copy()\n",
    "\n",
    "print(f\"✅ DataFrame final armado: {df_nuevo_final_23.shape[0]} filas x {df_nuevo_final_23.shape[1]} columnas\")\n",
    "print(\"Columnas incluidas:\")\n",
    "for col in df_nuevo_final_23.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########   BASE FINAL   ###### df_nuevo_final_23 ################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a0d1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### BASE INSOLVENCIA corte JULIO###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "401bca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BaseSoporteJulio01082025', 'Hoja1'])\n"
     ]
    }
   ],
   "source": [
    "def leer_excel_con_pandas(ruta_archivo):\n",
    "    # Leer archivo Excel, hoja por defecto (la primera)\n",
    "    insol = pd.read_excel(ruta_archivo,sheet_name=None)\n",
    "    return insol\n",
    "# E\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_excel_insolvencia = r\"C:\\Users\\acerquera\\OneDrive - Media Investment Optimization S.A\\Escritorio\\estadistica\\udea\\TESIS-QUIEBRA\\BASE DE DATOS\\INSOLVENCIA.xlsx\"  # Cambia si está en otra ruta\n",
    "    insol = leer_excel_con_pandas(ruta_excel_insolvencia)\n",
    "    print(insol.keys())  # Mostrar nombres de las hojas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar la primera hoja (o la que contenga los datos de insolvencia)\n",
    "nombre_hoja = list(insol.keys())[0]  # Toma la primera hoja\n",
    "df_insolvencia = insol[nombre_hoja]\n",
    "    \n",
    "print(f\"Dimensiones de la base de insolvencia: {df_insolvencia.shape}\")\n",
    "print(\"Columnas en la base de insolvencia:\")\n",
    "for col in df_insolvencia.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33576883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Columna PROCESO agregada al DataFrame final\n"
     ]
    }
   ],
   "source": [
    "# Preparar la unión de las bases\n",
    "def unir_bases_por_nit(df_nuevo_final_23, df_insolvencia):\n",
    "    \"\"\"\n",
    "    Une el DataFrame principal con la base de insolvencia por NIT\n",
    "    y crea variable riesgo basada en la presencia del NIT\n",
    "    \"\"\"\n",
    "    # Crear copias para no modificar los originales\n",
    "    df_main = df_nuevo_final_23.copy()  # Aquí usamos df_nuevo_final_23\n",
    "    df_insol = df_insolvencia.copy()\n",
    "    \n",
    "    # Asegurar que NIT sea string en ambos DataFrames\n",
    "    df_main['NIT'] = df_main['NIT'].astype(str).str.strip()\n",
    "    df_insol['NIT'] = df_insol['NIT'].astype(str).str.strip()\n",
    "    \n",
    "    # Crear variable riesgo basada en la presencia del NIT en la base de insolvencia\n",
    "    nits_insolvencia = set(df_insol['NIT'].unique())\n",
    "    df_main['riesgo'] = df_main['NIT'].isin(nits_insolvencia).astype(int)\n",
    "    \n",
    "    # Si existe la columna PROCESO, la incluimos en el DataFrame final\n",
    "    if 'PROCESO' in df_insol.columns:\n",
    "        # Tomar solo NIT y PROCESO de la base de insolvencia\n",
    "        df_insol_proceso = df_insol[['NIT', 'PROCESO']].drop_duplicates(subset='NIT')\n",
    "        \n",
    "        # Hacer LEFT JOIN para agregar la columna PROCESO\n",
    "        df_main = pd.merge(\n",
    "            df_main,\n",
    "            df_insol_proceso,\n",
    "            on='NIT',\n",
    "            how='left',\n",
    "            suffixes=('', '_insolvencia')\n",
    "        )\n",
    "        print(\"✓ Columna PROCESO agregada al DataFrame final\")\n",
    "    \n",
    "    return df_main\n",
    "\n",
    "# Ejecutar la unión de df_nuevo_final_23 con df_insolvencia\n",
    "df_final_completo_23 = unir_bases_por_nit(df_nuevo_final_23, df_insolvencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar distribución de la variable riesgo\n",
    "print(\"=\"*50)\n",
    "print(\"DISTRIBUCIÓN DE LA VARIABLE RIESGO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Conteo de empresas por categoría de riesgo\n",
    "conteo_riesgo = df_final_completo_23['riesgo'].value_counts().sort_index()\n",
    "total_empresas = len(df_final_completo_23)\n",
    "\n",
    "print(f\"\\nTotal de empresas en el DataFrame: {total_empresas:,}\")\n",
    "print(\"\\nDistribución:\")\n",
    "print(f\"Empresas SIN riesgo (0): {conteo_riesgo.get(0, 0):,} empresas → {conteo_riesgo.get(0, 0)/total_empresas:.2%}\")\n",
    "print(f\"Empresas CON riesgo (1): {conteo_riesgo.get(1, 0):,} empresas → {conteo_riesgo.get(1, 0)/total_empresas:.2%}\")\n",
    "\n",
    "# Verificación adicional\n",
    "print(f\"\\nVerificación:\")\n",
    "print(f\"Suma de categorías: {conteo_riesgo.get(0, 0) + conteo_riesgo.get(1, 0):,} empresas\")\n",
    "print(f\"Empresas con valor nulo en riesgo: {df_final_completo_23['riesgo'].isnull().sum()}\")\n",
    "\n",
    "# Mostrar algunos ejemplos de cada categoría\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EJEMPLOS DE EMPRESAS POR CATEGORÍA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Empresas SIN riesgo (5 ejemplos)\n",
    "print(\"\\n📈 5 empresas SIN riesgo (riesgo = 0):\")\n",
    "empresas_sin_riesgo = df_final_completo_23[df_final_completo_23['riesgo'] == 0].head()\n",
    "for i, (idx, row) in enumerate(empresas_sin_riesgo.iterrows(), 1):\n",
    "    print(f\"{i}. NIT: {row['NIT']} - {row.get('Razon social de la sociedad_balance', 'Nombre no disponible')}\")\n",
    "\n",
    "# Empresas CON riesgo (5 ejemplos)\n",
    "print(\"\\n⚠️  5 empresas CON riesgo (riesgo = 1):\")\n",
    "empresas_con_riesgo = df_final_completo_23[df_final_completo_23['riesgo'] == 1].head()\n",
    "for i, (idx, row) in enumerate(empresas_con_riesgo.iterrows(), 1):\n",
    "    nombre = row.get('Razon social de la sociedad_balance', 'Nombre no disponible')\n",
    "    proceso = row.get('PROCESO', 'Proceso no disponible')\n",
    "    print(f\"{i}. NIT: {row['NIT']} - {nombre} - Proceso: {proceso}\")\n",
    "\n",
    "# Estadísticas adicionales\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ESTADÍSTICAS ADICIONALES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Porcentaje de riesgo\n",
    "porcentaje_riesgo = df_final_completo_23['riesgo'].mean() * 100\n",
    "print(f\"Porcentaje global de empresas en riesgo: {porcentaje_riesgo:.2f}%\")\n",
    "\n",
    "# Si hay columna PROCESO, mostrar distribución\n",
    "if 'PROCESO' in df_final_completo_23.columns:\n",
    "    print(f\"\\nDistribución de tipos de proceso (solo empresas en riesgo):\")\n",
    "    procesos_riesgo = df_final_completo_23[df_final_completo_23['riesgo'] == 1]['PROCESO'].value_counts()\n",
    "    for proceso, conteo in procesos_riesgo.items():\n",
    "        porcentaje_proceso = (conteo / conteo_riesgo.get(1, 1)) * 100\n",
    "        print(f\"  - {proceso}: {conteo} empresas ({porcentaje_proceso:.1f}% del total en riesgo)\")\n",
    "\n",
    "# Balance de clases para machine learning\n",
    "print(f\"\\n🔍 Balance de clases para modelado:\")\n",
    "if porcentaje_riesgo < 10:\n",
    "    print(\"  - CLASE DESBALANCEADA: Menos del 10% en riesgo (considerar técnicas de balanceo)\")\n",
    "elif porcentaje_riesgo < 30:\n",
    "    print(\"  - MODERADAMENTE BALANCEADO: Entre 10-30% en riesgo\")\n",
    "else:\n",
    "    print(\"  - RELATIVAMENTE BALANCEADO: Más del 30% en riesgo\")\n",
    "\n",
    "print(f\"\\n📊 Resumen final:\")\n",
    "print(f\"   • Empresas analizadas: {total_empresas:,}\")\n",
    "print(f\"   • Empresas sanas (0): {conteo_riesgo.get(0, 0):,} ({100-porcentaje_riesgo:.1f}%)\")\n",
    "print(f\"   • Empresas en riesgo (1): {conteo_riesgo.get(1, 0):,} ({porcentaje_riesgo:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ab723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ANALIZAR LOS VALORES ÚNICOS EN LAS COLUMNAS DE PUNTO DE ENTRADA\n",
    "print(\"Valores únicos en Punto de Entrada_balance:\")\n",
    "print(df_final_completo_23['Punto de Entrada_balance'].value_counts())\n",
    "\n",
    "print(\"\\nValores únicos en Punto de Entrada_resultado:\")\n",
    "print(df_final_completo_23['Punto de Entrada_resultado'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce06ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna de categoría usando Punto de Entrada_balance (son iguales en ambas columnas)\n",
    "df_final_completo_23['Categoria'] = df_final_completo_23['Punto de Entrada_balance']\n",
    "\n",
    "# Verificar que se creó correctamente\n",
    "print(\"Distribución de categorías en el DataFrame completo:\")\n",
    "print(df_final_completo_23['Categoria'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo las empresas con riesgo = 1\n",
    "empresas_riesgo_23 = df_final_completo_23[df_final_completo_23['riesgo'] == 1].copy()\n",
    "\n",
    "print(f\"\\nTotal empresas en riesgo: {len(empresas_riesgo_23)}\")\n",
    "print(\"Distribución por categoría (empresas en riesgo):\")\n",
    "print(empresas_riesgo_23['Categoria'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44194b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla cruzada de categoría vs proceso\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUCIÓN DE PROCESOS POR CATEGORÍA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tabla_cruzada = pd.crosstab(\n",
    "    empresas_riesgo_23['Categoria'], \n",
    "    empresas_riesgo_23['PROCESO'],\n",
    "    margins=True,\n",
    "    margins_name=\"TOTAL\"\n",
    ")\n",
    "\n",
    "print(tabla_cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ab059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETALLE POR CATEGORÍA Y PROCESO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Procesos específicos que quieres analizar\n",
    "procesos = ['REORGANIZACIÓN EJECUCION', 'REORGANIZACIÓN EN TRAMITE', 'LIQUIDACIÓN JUDICIAL EN TRAMITE']\n",
    "categorias = ['Pymes-Individuales', 'Pymes-Separados', 'Plenas-Individuales', 'Plenas-Separados']\n",
    "\n",
    "for categoria in categorias:\n",
    "    print(f\"\\n📊 {categoria.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    empresas_categoria = empresas_riesgo_23[empresas_riesgo_23['Categoria'] == categoria]\n",
    "    total_categoria = len(empresas_categoria)\n",
    "    \n",
    "    if total_categoria == 0:\n",
    "        print(\"   No hay empresas en riesgo en esta categoría\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"   Total empresas en riesgo: {total_categoria}\")\n",
    "    \n",
    "    for proceso in procesos:\n",
    "        nits_proceso = empresas_categoria[empresas_categoria['PROCESO'] == proceso]['NIT'].tolist()\n",
    "        cantidad = len(nits_proceso)\n",
    "        \n",
    "        if cantidad > 0:\n",
    "            porcentaje = (cantidad / total_categoria) * 100\n",
    "            print(f\"\\n   • {proceso}: {cantidad} empresas ({porcentaje:.1f}%)\")\n",
    "            print(f\"     NITs: {nits_proceso}\")\n",
    "        else:\n",
    "            print(f\"\\n   • {proceso}: 0 empresas (0.0%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2960f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'df_final_completo_23.xlsx' guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame df_final_completo_23 como archivo Excel\n",
    "df_final_completo_23.to_excel('df_final_completo_23.xlsx', index=False)\n",
    "print(\"Archivo 'df_final_completo_23.xlsx' guardado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b59d6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### DATAFRAME ---DF_FINAL_COMPLETO_23 ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77702cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TABLA DE MEDIANAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8657df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Helpers (los mismos que ya usamos) =========\n",
    "def bootstrap_ci_delta_mediana(x, y, n_boot=5000, ci=95, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.asarray(x, dtype=float); x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y, dtype=float); y = y[~np.isnan(y)]\n",
    "    n1, n2 = len(x), len(y)\n",
    "    diffs = np.empty(n_boot)\n",
    "    for i in range(n_boot):\n",
    "        xb = rng.choice(x, size=n1, replace=True)\n",
    "        yb = rng.choice(y, size=n2, replace=True)\n",
    "        diffs[i] = np.median(xb) - np.median(yb)\n",
    "    alpha = 1 - ci/100.0\n",
    "    lo, hi = np.quantile(diffs, [alpha/2, 1 - alpha/2])\n",
    "    delta_obs = float(np.median(x) - np.median(y))\n",
    "    return delta_obs, float(lo), float(hi)\n",
    "\n",
    "def permutacion_pvalor_mediana(x, y, n_perm=10000, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.asarray(x, dtype=float); x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y, dtype=float); y = y[~np.isnan(y)]\n",
    "    n1, n2 = len(x), len(y)\n",
    "    z = np.concatenate([x, y])\n",
    "    delta_obs = float(np.median(x) - np.median(y))\n",
    "    stats = np.empty(n_perm)\n",
    "    for i in range(n_perm):\n",
    "        rng.shuffle(z)\n",
    "        xp = z[:n1]; yp = z[n1:]\n",
    "        stats[i] = np.median(xp) - np.median(yp)\n",
    "    p_two = (np.sum(np.abs(stats) >= abs(delta_obs)) + 1) / (n_perm + 1)\n",
    "    return delta_obs, float(p_two)\n",
    "\n",
    "def resumen_dif_medianas(\n",
    "    df, variables, col_grupo='riesgo',\n",
    "    n_boot=5000, n_perm=10000, random_state=42\n",
    "):\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    filas = []\n",
    "    for var in variables:\n",
    "        if var not in df.columns:\n",
    "            continue\n",
    "        # forzar numérico\n",
    "        serie = pd.to_numeric(df[var], errors='coerce')\n",
    "        g0 = serie[df[col_grupo] == 0].dropna().values  # No Riesgo\n",
    "        g1 = serie[df[col_grupo] == 1].dropna().values  # Riesgo\n",
    "        if len(g0) < 10 or len(g1) < 10:\n",
    "            continue\n",
    "\n",
    "        # Medianas\n",
    "        med0 = float(np.median(g0))\n",
    "        med1 = float(np.median(g1))\n",
    "\n",
    "        # Δ mediana + IC95% por bootstrap\n",
    "        dmed, lo, hi = bootstrap_ci_delta_mediana(g0, g1, n_boot=n_boot, ci=95, random_state=random_state)\n",
    "\n",
    "        # p-valor por permutación (diferencia de medianas)\n",
    "        _, p_perm = permutacion_pvalor_mediana(g0, g1, n_perm=n_perm, random_state=random_state)\n",
    "\n",
    "        # (referencial) t-test de medias (Welch)\n",
    "        t_stat, p_t = ttest_ind(g0, g1, equal_var=False, nan_policy='omit')\n",
    "\n",
    "        filas.append({\n",
    "            'Variable': var,\n",
    "            'Mediana_NR': med0,\n",
    "            'Mediana_R': med1,\n",
    "            'Delta_mediana_NR_minus_R': dmed,\n",
    "            'IC95_lo': lo,\n",
    "            'IC95_hi': hi,\n",
    "            'Estadistico_t_media': float(t_stat),   # t-test de MEDIAS (referencial)\n",
    "            'p_valor_t_media': float(p_t),\n",
    "            'p_valor_perm_mediana': p_perm          # prueba para MEDIANAS\n",
    "        })\n",
    "\n",
    "    res = pd.DataFrame(filas)\n",
    "    if not res.empty:\n",
    "        res = res.sort_values('p_valor_perm_mediana', ascending=True).reset_index(drop=True)\n",
    "        # estrellas de significancia por p de permutación\n",
    "        res['Sig_perm'] = res['p_valor_perm_mediana'].apply(\n",
    "            lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''\n",
    "        )\n",
    "    return res\n",
    "\n",
    "# ========= EJECUCIÓN con 21 variables =========\n",
    "variables_analisis = [\n",
    "    'raz', 'teso', 'rota', 'margenb', 'margen', 'ractiv', 'rpatri', 'cicop',\n",
    "    'endeu', 'niven', 'nivel_endeudamiento_alt', 'apalc', 'apallar', 'apalfin',\n",
    "    'apaltot', 'cobint', 'activos_pasivos', 'pasivo_corto_pasivo_total',\n",
    "    'margen_operacional', 'ctno_ventas_preciso', 'fclo_ventas'\n",
    "]\n",
    "\n",
    "# Normaliza la columna de grupo a 0/1 por si viene como texto\n",
    "df_final_completo_23['riesgo'] = (\n",
    "    df_final_completo_23['riesgo']\n",
    "      .replace({'No Riesgo':0,'Riesgo':1,'NR':0,'R':1})\n",
    "      .astype('int64')\n",
    ")\n",
    "\n",
    "# Asegura numérico y limpia inf\n",
    "df_final_completo_23 = df_final_completo_23.replace([np.inf, -np.inf], np.nan)\n",
    "for v in variables_analisis:\n",
    "    if v in df_final_completo_23.columns:\n",
    "        df_final_completo_23[v] = pd.to_numeric(df_final_completo_23[v], errors='coerce')\n",
    "\n",
    "# Corre resumen con TODAS las variables\n",
    "tabla = resumen_dif_medianas(\n",
    "    df_final_completo_23,\n",
    "    variables=variables_analisis,\n",
    "    col_grupo='riesgo',\n",
    "    n_boot=5000,     # sube/baja según tiempo disponible\n",
    "    n_perm=10000,    # sube para p más fino\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Muestra y guarda\n",
    "print(tabla.to_string(index=False))\n",
    "tabla.to_excel('resumen_diferencia_mediana_21vars.xlsx', index=False)\n",
    "print(\"\\n✅ Archivo guardado: 'resumen_diferencia_mediana_21vars.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc809b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Análisis 2023: Diferencia de medianas (NR vs R) con:\n",
    "  - IC 95% por Bootstrap percentil (estratificado por grupo)\n",
    "  - p-valor CORRECTO bicaudal por Test de Permutación\n",
    "  - (Opcional) Ajuste FDR y Tamaño del efecto A de Vargha–Delaney\n",
    "Entrada: df_final_completo_23 con columna 'riesgo' (0/1) y variables financieras.\n",
    "Salida: Consola + Excel 'resultados_bootstrap_2023.xlsx'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Helpers estadísticos\n",
    "# =============================================================================\n",
    "\n",
    "def bootstrap_ci_delta_mediana(x, y, n_bootstrap=5000, ci=95, random_state=42, progress_each=1000):\n",
    "    \"\"\"\n",
    "    IC bootstrap percentil (estratificado) para Δ̃ = mediana(x) - mediana(y).\n",
    "    Retorna: (delta_obs, ic_lo, ic_hi)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.asarray(x, dtype=float); x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y, dtype=float); y = y[~np.isnan(y)]\n",
    "    n1, n2 = len(x), len(y)\n",
    "\n",
    "    boot_diffs = np.empty(n_bootstrap, dtype=float)\n",
    "    for i in range(n_bootstrap):\n",
    "        if progress_each and (i % progress_each == 0):\n",
    "            print(f\"  Progreso bootstrap: {i}/{n_bootstrap} iteraciones\")\n",
    "        xb = rng.choice(x, size=n1, replace=True)\n",
    "        yb = rng.choice(y, size=n2, replace=True)\n",
    "        boot_diffs[i] = np.median(xb) - np.median(yb)\n",
    "\n",
    "    print(f\"  Progreso bootstrap: {n_bootstrap}/{n_bootstrap} iteraciones - COMPLETADO\")\n",
    "    alpha = (100 - ci) / 100.0\n",
    "    lo, hi = np.quantile(boot_diffs, [alpha/2, 1 - alpha/2])\n",
    "\n",
    "    delta_obs = np.median(x) - np.median(y)\n",
    "    return float(delta_obs), float(lo), float(hi)\n",
    "\n",
    "\n",
    "def permutation_pvalue_two_sided(x, y, n_perm=10000, random_state=42, progress_each=1000):\n",
    "    \"\"\"\n",
    "    p-valor bicaudal por test de permutación para Δ̃ = mediana(x) - mediana(y).\n",
    "    H0: mediana_NR = mediana_R ; H1: distintas\n",
    "    Retorna: (delta_obs, p_two)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.asarray(x, dtype=float); x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y, dtype=float); y = y[~np.isnan(y)]\n",
    "    n1, n2 = len(x), len(y)\n",
    "    z = np.concatenate([x, y])\n",
    "\n",
    "    delta_obs = np.median(x) - np.median(y)\n",
    "    stats = np.empty(n_perm, dtype=float)\n",
    "\n",
    "    for i in range(n_perm):\n",
    "        if progress_each and (i % progress_each == 0):\n",
    "            print(f\"  Progreso permutación: {i}/{n_perm} permutaciones\")\n",
    "        rng.shuffle(z)\n",
    "        x_p = z[:n1]\n",
    "        y_p = z[n1:]\n",
    "        stats[i] = np.median(x_p) - np.median(y_p)\n",
    "\n",
    "    # p-valor bicaudal (corrección +1 para evitar 0 exacto)\n",
    "    p_two = (np.sum(np.abs(stats) >= abs(delta_obs)) + 1) / (n_perm + 1)\n",
    "    return float(delta_obs), float(p_two)\n",
    "\n",
    "\n",
    "def vargha_delaney_A(x, y):\n",
    "    \"\"\"\n",
    "    Tamaño del efecto A de Vargha–Delaney: A = U / (n1 * n2).\n",
    "    A = 0.5 sin efecto; A > 0.5 NR domina; A < 0.5 R domina.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float); x = x[~np.isnan(x)]\n",
    "    y = np.asarray(y, dtype=float); y = y[~np.isnan(y)]\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        U, _ = mannwhitneyu(x, y, alternative='two-sided', method='asymptotic')\n",
    "    except TypeError:\n",
    "        U, _ = mannwhitneyu(x, y, alternative='two-sided')\n",
    "    return float(U) / (len(x) * len(y))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Núcleo de análisis por variable\n",
    "# =============================================================================\n",
    "\n",
    "def bootstrap_median_diff_balanced(data1, data2, n_bootstrap=5000, ci=95, random_state=42,\n",
    "                                   n_perm=10000, progress_each=1000):\n",
    "    \"\"\"\n",
    "    Calcula Δ̃ observada, IC 95% por bootstrap y p-valor bicaudal por permutación.\n",
    "    Retorna dict con: diferencia_mediana, IC, p_value, n_nr, n_r.\n",
    "    \"\"\"\n",
    "    x = data1.dropna().values\n",
    "    y = data2.dropna().values\n",
    "    n1, n2 = len(x), len(y)\n",
    "    ratio = n1 / max(n2, 1)\n",
    "    print(f\"  Muestra: NR={n1}, R={n2}, Ratio={ratio:.1f}:1\")\n",
    "\n",
    "    # IC bootstrap (estratificado)\n",
    "    delta_obs, ic_lo, ic_hi = bootstrap_ci_delta_mediana(\n",
    "        x, y, n_bootstrap=n_bootstrap, ci=ci, random_state=random_state, progress_each=progress_each\n",
    "    )\n",
    "\n",
    "    # p-valor por permutación (dos colas)\n",
    "    delta_chk, p_two = permutation_pvalue_two_sided(\n",
    "        x, y, n_perm=n_perm, random_state=random_state, progress_each=progress_each\n",
    "    )\n",
    "    # sanity: delta_chk ≈ delta_obs\n",
    "    p_two = max(p_two, 1/(n_perm+1))  # evitar p=0\n",
    "\n",
    "    return {\n",
    "        'diferencia_mediana': delta_obs,\n",
    "        'ic_inferior': ic_lo,\n",
    "        'ic_superior': ic_hi,\n",
    "        'p_value': p_two,\n",
    "        'n_nr': int(n1),\n",
    "        'n_r': int(n2)\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Barrido completo y reporte\n",
    "# =============================================================================\n",
    "\n",
    "def analisis_bootstrap_completo_corregido(df, variables_analisis, grupo_riesgo='riesgo',\n",
    "                                          n_bootstrap=5000, n_perm=10000, random_state=42,\n",
    "                                          progress_each=1000, alerta_min_r=500):\n",
    "    \"\"\"\n",
    "    Recorre variables, imprime resultados y devuelve diccionario con métricas por variable.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANÁLISIS BOOTSTRAP - COMPARACIÓN DE MEDIANAS (CORREGIDO)\")\n",
    "    print(\"=\" * 80)\n",
    "    total = len(df)\n",
    "    n_nr_tot = int((df[grupo_riesgo]==0).sum())\n",
    "    n_r_tot  = int((df[grupo_riesgo]==1).sum())\n",
    "    print(f\"Total empresas: {total:,}\")\n",
    "    print(f\"Sin riesgo (0): {n_nr_tot:,} ({n_nr_tot/total*100:.1f}%)\")\n",
    "    print(f\"Con riesgo (1): {n_r_tot:,} ({n_r_tot/total*100:.1f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    resultados = {}\n",
    "\n",
    "    for variable in variables_analisis:\n",
    "        print(f\"\\n🔍 Analizando: {variable}\")\n",
    "        nr_data = df.loc[df[grupo_riesgo] == 0, variable]\n",
    "        r_data  = df.loc[df[grupo_riesgo] == 1, variable]\n",
    "\n",
    "        n_nr = nr_data.notna().sum()\n",
    "        n_r  = r_data.notna().sum()\n",
    "        if n_nr < 10 or n_r < 10:\n",
    "            print(f\"  ⚠️  Datos insuficientes - Saltando variable (NR={n_nr}, R={n_r})\")\n",
    "            continue\n",
    "\n",
    "        res = bootstrap_median_diff_balanced(\n",
    "            nr_data, r_data,\n",
    "            n_bootstrap=n_bootstrap, ci=95,\n",
    "            random_state=random_state, n_perm=n_perm,\n",
    "            progress_each=progress_each\n",
    "        )\n",
    "        resultados[variable] = res\n",
    "\n",
    "        p = res['p_value']\n",
    "        signif = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"\"\n",
    "        print(f\"  📊 Diferencia medianas: {res['diferencia_mediana']:+.4f} {signif}\")\n",
    "        print(f\"  📈 IC 95%: [{res['ic_inferior']:+.4f}, {res['ic_superior']:+.4f}]\")\n",
    "        print(f\"  🎯 p-value: {p:.4g} {signif}\")\n",
    "\n",
    "        direccion = \"MAYOR en empresas sin riesgo\" if res['diferencia_mediana'] > 0 else \"MENOR en empresas sin riesgo\"\n",
    "        print(f\"  💡 Interpretación: {variable} es {direccion}\")\n",
    "\n",
    "        if n_r < alerta_min_r:\n",
    "            print(f\"  ⚠️  ALERTA: Muestra riesgo pequeña (n={n_r}), interpretar con cautela\")\n",
    "\n",
    "    return resultados\n",
    "\n",
    "\n",
    "def generar_reporte_final_corregido(resultados, df, variables_analisis, grupo_riesgo='riesgo',\n",
    "                                    aplicar_fdr=True, ruta_salida='resultados_bootstrap_2023.xlsx'):\n",
    "    \"\"\"\n",
    "    Genera:\n",
    "      - DataFrame con Δ̃, IC, p, (opcional) p_adj_fdr y A_VD\n",
    "      - Impresión ejecutiva\n",
    "      - Guarda Excel con el resumen\n",
    "    Retorna df_res.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📊 REPORTE EJECUTIVO - BOOTSTRAP CORREGIDO\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    rows = []\n",
    "    for var, res in resultados.items():\n",
    "        rows.append({\n",
    "            'Variable': var,\n",
    "            'Diferencia': res['diferencia_mediana'],\n",
    "            'IC_inf': res['ic_inferior'],\n",
    "            'IC_sup': res['ic_superior'],\n",
    "            'p_value': res['p_value'],\n",
    "            'n_NR': res['n_nr'],\n",
    "            'n_R': res['n_r']\n",
    "        })\n",
    "    df_res = pd.DataFrame(rows).sort_values('p_value')\n",
    "\n",
    "    # Tamaño del efecto A de Vargha–Delaney\n",
    "    A_vals = []\n",
    "    for var in df_res['Variable']:\n",
    "        x = df.loc[df[grupo_riesgo]==0, var]\n",
    "        y = df.loc[df[grupo_riesgo]==1, var]\n",
    "        A_vals.append(vargha_delaney_A(x, y))\n",
    "    df_res['A_VD'] = A_vals\n",
    "\n",
    "    # Ajuste FDR (opcional)\n",
    "    if aplicar_fdr:\n",
    "        try:\n",
    "            from statsmodels.stats.multitest import multipletests\n",
    "            rej, p_adj, _, _ = multipletests(df_res['p_value'].values, alpha=0.05, method='fdr_bh')\n",
    "            df_res['p_adj_fdr'] = p_adj\n",
    "            df_res['rechaza_fdr'] = rej\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  No se pudo aplicar FDR: {e}\")\n",
    "            df_res['p_adj_fdr'] = np.nan\n",
    "            df_res['rechaza_fdr'] = np.nan\n",
    "\n",
    "    # Listados rápidos\n",
    "    sig_mask = df_res['p_value'] < 0.05\n",
    "    vars_significativas = df_res.loc[sig_mask, 'Variable'].tolist()\n",
    "    vars_no_significativas = df_res.loc[~sig_mask, 'Variable'].tolist()\n",
    "\n",
    "    print(f\"\\n✅ VARIABLES SIGNIFICATIVAS (p < 0.05): {len(vars_significativas)}\")\n",
    "    for _, r in df_res.loc[sig_mask].iterrows():\n",
    "        p = r['p_value']\n",
    "        signif = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\"\n",
    "        print(f\"   • {r['Variable']}: {r['Diferencia']:+.4f} (p={p:.4g}) {signif}\")\n",
    "\n",
    "    print(f\"\\n❌ VARIABLES NO SIGNIFICATIVAS: {len(vars_no_significativas)}\")\n",
    "    for var in vars_no_significativas[:5]:\n",
    "        r = df_res[df_res['Variable'] == var].iloc[0]\n",
    "        print(f\"   • {var}: {r['Diferencia']:+.4f} (p={r['p_value']:.4g})\")\n",
    "    if len(vars_no_significativas) > 5:\n",
    "        print(f\"   ... y {len(vars_no_significativas) - 5} más\")\n",
    "\n",
    "    # Top-5 por magnitud |Δ̃|\n",
    "    top_efecto = (df_res.assign(abs_eff=lambda d: d['Diferencia'].abs())\n",
    "                        .sort_values('abs_eff', ascending=False)\n",
    "                        .head(5))\n",
    "    print(f\"\\n🎯 TOP 5 VARIABLES CON MAYOR EFECTO ABSOLUTO:\")\n",
    "    for _, r in top_efecto.iterrows():\n",
    "        print(f\"   • {r['Variable']}: {r['Diferencia']:+.4f} (magnitud: {abs(r['Diferencia']):.4f})\")\n",
    "\n",
    "    # Guardar Excel\n",
    "    df_res.to_excel(ruta_salida, index=False)\n",
    "    print(f\"\\n✅ Resultados CORREGIDOS guardados en '{ruta_salida}'\")\n",
    "    return df_res\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) EJECUCIÓN PARA 2023 (usa df_final_completo_23)\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Analizando 2023 con bootstrap + permutación bicaudal…\")\n",
    "\n",
    "    # Parámetros\n",
    "    N_BOOT = 5000        # IC bootstrap (sube si quieres IC más finos)\n",
    "    N_PERM = 10000       # permutación (p mínimo ≈ 1/(N_PERM+1)); sube a 50_000–100_000 si quieres p más granular\n",
    "    RNG_SEED = 42\n",
    "    PROGRESS_EACH = 1000 # 0 para silenciar progreso\n",
    "\n",
    "    # ➜ Asegúrate de tener cargado df_final_completo_23 con 'riesgo' y estas variables:\n",
    "    variables_analisis = [\n",
    "        'raz', 'teso', 'rota', 'margenb', 'margen', 'ractiv', 'rpatri', 'cicop',\n",
    "        'endeu', 'niven', 'nivel_endeudamiento_alt', 'apalc', 'apallar', 'apalfin',\n",
    "        'apaltot', 'cobint', 'activos_pasivos', 'pasivo_corto_pasivo_total',\n",
    "        'margen_operacional', 'ctno_ventas_preciso', 'fclo_ventas'\n",
    "    ]\n",
    "\n",
    "    # Ejecutar análisis 2023\n",
    "    resultados_2023 = analisis_bootstrap_completo_corregido(\n",
    "        df_final_completo_23,\n",
    "        variables_analisis,\n",
    "        grupo_riesgo='riesgo',\n",
    "        n_bootstrap=N_BOOT,\n",
    "        n_perm=N_PERM,\n",
    "        random_state=RNG_SEED,\n",
    "        progress_each=PROGRESS_EACH,\n",
    "        alerta_min_r=500\n",
    "    )\n",
    "\n",
    "    # Generar reporte final y guardar Excel\n",
    "    df_resumen_2023 = generar_reporte_final_corregido(\n",
    "        resultados_2023,\n",
    "        df_final_completo_23,\n",
    "        variables_analisis,\n",
    "        grupo_riesgo='riesgo',\n",
    "        aplicar_fdr=True,\n",
    "        ruta_salida='resultados_bootstrap_2023.xlsx'\n",
    "    )\n",
    "\n",
    "    # (Opcional) Resumen de variables a destacar\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📈 2023 — RESUMEN DE CAMBIOS A DESTACAR\")\n",
    "    print(\"=\" * 80)\n",
    "    variables_que_cambiaron = ['niven', 'apaltot', 'apallar', 'apalfin', 'endeu', 'ctno_ventas_preciso']\n",
    "    for var in variables_que_cambiaron:\n",
    "        if var in resultados_2023 and resultados_2023[var]['p_value'] < 0.05:\n",
    "            print(f\"   • {var}: p = {resultados_2023[var]['p_value']:.4g}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
